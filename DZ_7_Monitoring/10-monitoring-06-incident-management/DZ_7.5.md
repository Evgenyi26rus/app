# Домашнее задание к занятию 17 «Инцидент-менеджмент»

## Задание

Составьте постмортем на основе реального сбоя системы GitHub в 2018 году.

Информацию о сбое можно изучить по ссылкам ниже:

* [краткое описание на русском языке](https://habr.com/ru/post/427301/);
* [развёрнутое описание на английском языке](https://github.blog/2018-10-30-oct21-post-incident-analysis/).


### Краткое описание инцидента:

С 22:52 (21.10) по UTC пропадали новые созданные Issue записи/комментарии после перезагрузки страницы GitHub. Сборка страниц остановлена.

### Предшествующие события:

Плановые работы по техническому обслуживанию для замены вышедшего из строя оптического оборудования 100G.

### Причина инцидента:

Эти работы привели к потере связи между нашим сетевым центром на Восточном побережье США и нашим основным центром обработки данных на Восточном побережье США. Связь между этими местоположениями была восстановлена за 43 секунды, но это кратковременное отключение вызвало цепочку событий, которые привели к 24 часам и 11 минутам сбоя в обслуживании. А именно пострадали несколько сетевых разделов и последующим сбоем базы данных, что привело к появлению непоследовательной информации на нашем веб-сайте.

### Воздействие:

В течении суток была не доступна сборка страниц в Git, отключен Webhooks. Инцидент повлиял только на метаданные веб-сайтов, хранящиеся в базах данных MySQL, такие как Issue и PR.


### Обнаружение:

Были получены оповещения/алерты о повышенном количестве ошибок и недоступности сервиса. Инженерами и координаторами инцидента был заведён инцидент с соответствующим приоритетом (красный статус сайта).

### Реакция:

Сервис был восстановлен через 24 часа и 11 минут.
Устранение инцидента проходило в несколько этапов, с повторной остановкой сервиса после временного запуска.
Первое решение было предоставлено через 9 часов 20 минут. После 9 часов работы сервис был остановлен.
Второе решение было предоставлено через 1 час после остановки. Далее отладка процессов.

### Восстановление:

Восстановление данных из резервных копий, синхронизация реплик на обоих поборежьях США, возвращение к стабильной топологии обслуживания, возобновление обработки заданий, поставленных в очередь.

### Таймплайн:

- 21 октября 2018 22:52 UTC плановые работы по техническому обслуживанию для замены вышедшего из строя оптического оборудования 100G
- 21 октября 2018 22:52 UTC Сбой в БД между Восточным и Западным побережьем США
- 21 октября 2018 22:54 UTC Сработал мониторинг с алертами
- 21 октября 2018 23:02 UTC Определение инженерами причины оповещений
- 21 октября 2018 23:07 UTC Заблокирован внутренний инструмент развёртывания
- 21 октября 2018 23:07 - 23:11 UTC Регистрация инцидента и установка нужного статуса ему.
- 21 октября 2018 23:13 UTC Привлечены дополнительные инженеры и разработчики БД. Выработка вариантов решения и принятие итоговой стратегии по восстановлению и синхронизацию данных.
- 21 октября 2018 23:19 UTC Остановка доставки webhook и сборки GitHub Pages
- 22 октября 2018 00:05 UTC Начало восстановительных работ: восстановление данных из резервных копий, синхронизация реплик на обоих сайтах, возвращение к стабильной топологии обслуживания, возобновление обработки заданий, поставленных в очередь. Информирование пользователей о начале работ.
- 22 октября 2018 00:41 UTC Запущен процесс резервного копирования для всех затронутых кластеров MySQL
- 22 октября 2018 06:51 UTC Несколько кластеров завершили восстановление из резервных копий в ЦОД-е и начали реплицировать новые данные с Западного побережья
- 22 октября 2018 07:46 UTC Опубликована запись в блоге GitHub на своей странице о проблеме, её описании и ближайшем восстановлении сервиса.
- 22 октября 2018 11:12 UTC Все первичные базы данных снова были установлены на Восточном побережье США. Перераспределение нагрузки на чтение по большему пулу реплик чтения. Продолжение восстановления репликаций.
- 22 октября 2018 13:15 UTC Пиковая нагрузка на трафик GitHub.com и ухудшение восстановление репликаций, замедление.
- 22 октября 2018 16:24 UTC Переход на исходную топологию, решив насущные проблемы с задержкой / доступностью
- 22 октября 2018 16:45 UTC Балансировка возросшей нагрузки, связанной с невыполненной работой, потенциально перегружающей наших партнеров по экосистеме уведомлениями, восстановление работы сервисов на 100%. Было зарегистрировано более пяти миллионов событий перехвата и 80 тысяч сборок страниц в очереди. Повторно включили обработку этих данных, обработали ~ 200 000 полезных загрузок webhook, которые пережили внутренний TTL и были удалены. Обнаружив это, приостановили обработку и внесли изменение, чтобы увеличить этот TTL на некоторое время.
- 22 октября 2018 23:03 UTC Все ожидающие сборки webhooks и Pages были обработаны, и целостность и надлежащая работа всех систем были подтверждены. 

### Действия по недопущению повторения инцидента:

1. Изменена конфигурация Orchestrator, чтобы предотвратить распространение первичных баз данных через региональные границы. 
2. Ускорили переход на новый механизм отчетов о состоянии, который более детальней описывает проблемы. В будущем будут отображаться различные компоненты платформы, чтобы пользователи знали состояние каждого сервиса.
3. За несколько недель до этого инцидента была запущена общекорпоративная инженерная инициатива по поддержке обслуживания трафика GitHub из нескольких центров обработки данных в активном дизайне. Цель этого проекта - поддерживать резервирование N + 1 на уровне объекта. Цель этой работы - допустить полный отказ одного центра обработки данных без воздействия на пользователя. Это серьезная работа, которая займет некоторое время, но мы считаем, что несколько сайтов с хорошими связями в одной географии обеспечивают хороший набор компромиссов. Этот инцидент придал срочности инициативе.
4. Начнем систематическую практику проверки сценариев сбоев до того, как они смогут повлиять на пользователя. Эта работа будет включать будущие инвестиции в внедрение сбоев и инструменты разработки хаоса в GitHub.




